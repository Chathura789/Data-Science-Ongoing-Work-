{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Intro to Deep learning .ipynb","provenance":[],"authorship_tag":"ABX9TyMsAhLRNfkh4+RXQR/qmLme"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","input_data = np.array([3, 5])"],"metadata":{"id":"f3OFzYhGNhQ6","executionInfo":{"status":"ok","timestamp":1645529700799,"user_tz":0,"elapsed":329,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def relu(input):\n","    '''Define your relu activation function here'''\n","    # Calculate the value for the output of the relu function: output\n","    output = max(0, input)\n","    \n","    # Return the value just calculated\n","    return(output)\n","\n","# Calculate node 0 value: node_0_output\n","node_0_input = (input_data * weights['node_0']).sum()\n","node_0_output = relu(node_0_input)\n","\n","# Calculate node 1 value: node_1_output\n","node_1_input = (input_data * weights['node_1']).sum()\n","node_1_output = relu(node_1_input)\n","\n","# Put node values into array: hidden_layer_outputs\n","hidden_layer_outputs = np.array([node_0_output, node_1_output])\n","\n","# Calculate model output (do not apply relu)\n","model_output = (hidden_layer_outputs * weights['output']).sum()\n","\n","# Print model output\n","print(model_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"XAm-E5LMNZnB","executionInfo":{"status":"error","timestamp":1645529707788,"user_tz":0,"elapsed":349,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}},"outputId":"c2abe8cb-2e6b-43f6-bc84-b5ef19ec3e38"},"execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-efb3d7493fcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Calculate node 0 value: node_0_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnode_0_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mnode_0_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_0_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-yem9vCNFhK"},"outputs":[],"source":["# Define predict_with_network()\n","def predict_with_network(input_data_row, weights):\n","\n","    # Calculate node 0 value\n","    node_0_input = (input_data_row * weights['node_0']).sum()\n","    node_0_output = relu(node_0_input)\n","\n","    # Calculate node 1 value\n","    node_1_input = (input_data_row * weights['node_1']).sum()\n","    node_1_output = relu(node_1_input)\n","\n","    # Put node values into array: hidden_layer_outputs\n","    hidden_layer_outputs = np.array([node_0_output, node_1_output])\n","    \n","    # Calculate model output\n","    input_to_final_layer = (hidden_layer_outputs * weights['output']).sum()\n","    model_output = relu(input_to_final_layer)\n","    \n","    # Return model output\n","    return(model_output)\n","\n","\n","# Create empty list to store prediction results\n","results = []\n","for input_data_row in input_data:\n","    # Append prediction to results\n","    results.append(predict_with_network(input_data_row, weights))\n","\n","# Print results\n","print(results)\n","        "]},{"cell_type":"code","source":["n_updates = 20\n","mse_hist = []\n","\n","# Iterate over the number of updates\n","for i in range(n_updates):\n","    # Calculate the slope: slope\n","    slope = get_slope(input_data, target, weights)\n","    \n","    # Update the weights: weights\n","    weights = weights - 0.01 * slope\n","    \n","    # Calculate mse with new weights: mse\n","    mse = get_mse(input_data, target, weights)\n","    \n","    # Append the mse to mse_hist\n","    mse_hist.append(mse)\n","\n","# Plot the mse history\n","plt.plot(mse_hist)\n","plt.xlabel('Iterations')\n","plt.ylabel('Mean Squared Error')\n","plt.show()\n"],"metadata":{"id":"yQrQaCcjWz8T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import necessary modules\n","import keras\n","from keras.layers import Dense\n","from keras.models import Sequential\n","\n","# Specify the model\n","n_cols = predictors.shape[1]\n","model = Sequential()\n","model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Fit the model\n","model.fit(predictors, target)\n"],"metadata":{"id":"RFakh4RfeoBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import necessary modules\n","import keras\n","from keras.layers import Dense\n","from keras.models import Sequential\n","from keras.utils import to_categorical\n","\n","# Convert the target to categorical: target\n","target = to_categorical(df.survived)\n","\n","# Set up the model\n","model = Sequential()\n","\n","# Add the first layer\n","model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n","\n","# Add the output layer\n","model.add(Dense(2, activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='sgd', \n","              loss='categorical_crossentropy', \n","              metrics=['accuracy'])\n","\n","# Fit the model\n","model.fit(predictors, target)\n"],"metadata":{"id":"KMKJxunEg3bK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import the SGD optimizer\n","from keras.optimizers import SGD\n","\n","# Create list of learning rates: lr_to_test\n","lr_to_test = [.000001, 0.01, 1]\n","\n","# Loop over learning rates\n","for lr in lr_to_test:\n","    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n","    \n","    # Build new model to test, unaffected by previous models\n","    model = get_new_model()\n","    \n","    # Create SGD optimizer with specified learning rate: my_optimizer\n","    my_optimizer = SGD(lr=lr)\n","    \n","    # Compile the model\n","    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy')\n","    \n","    # Fit the model\n","    model.fit(predictors, target)\n"],"metadata":{"id":"Wf2yABnxlFTo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the number of columns in predictors: n_cols\n","n_cols = predictors.shape[1]\n","input_shape = (n_cols,)\n","\n","# Specify the model\n","model = Sequential()\n","model.add(Dense(100, activation='relu', input_shape = input_shape))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(2, activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Fit the model\n","hist = model.fit(predictors, target, validation_split=0.3)\n"],"metadata":{"id":"alOO7Rn9npZj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import EarlyStopping\n","from keras.callbacks import EarlyStopping\n","\n","# Save the number of columns in predictors: n_cols\n","n_cols = predictors.shape[1]\n","input_shape = (n_cols,)\n","\n","# Specify the model\n","model = Sequential()\n","model.add(Dense(100, activation='relu', input_shape = input_shape))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(2, activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Define early_stopping_monitor\n","early_stopping_monitor = EarlyStopping(patience=2)\n","\n","# Fit the model\n","model.fit(predictors, target, epochs=30, validation_split=0.3, callbacks=[early_stopping_monitor])\n"],"metadata":{"id":"JbCT4ykooMWj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define early_stopping_monitor\n","early_stopping_monitor = EarlyStopping(patience=2)\n","\n","# Create the new model: model_2\n","model_2 = Sequential()\n","\n","# Add the first and second layers\n","model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n","model_2.add(Dense(100, activation='relu'))\n","\n","# Add the output layer\n","model_2.add(Dense(2, activation='softmax'))\n","\n","# Compile model_2\n","model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Fit model_1\n","model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n","\n","# Fit model_2\n","model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n","\n","# Create the plot\n","plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n","plt.xlabel('Epochs')\n","plt.ylabel('Validation score')\n","plt.show()\n"],"metadata":{"id":"RNpVHeZMo3_m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The input shape to use in the first hidden layer\n","input_shape = (n_cols,)\n","\n","# Create the new model: model_2\n","model_2 = Sequential()\n","\n","# Add the first, second, and third hidden layers\n","model_2.add(Dense(50, activation='relu', input_shape=input_shape))\n","model_2.add(Dense(50, activation='relu'))\n","model_2.add(Dense(50, activation='relu'))\n","\n","# Add the output layer\n","model_2.add(Dense(2, activation='softmax'))\n","\n","# Compile model_2\n","model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Fit model 1\n","model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n","\n","# Fit model 2\n","model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n","\n","# Create the plot\n","plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n","plt.xlabel('Epochs')\n","plt.ylabel('Validation score')\n","plt.show()\n"],"metadata":{"id":"Mdzh19GpqNU5"},"execution_count":null,"outputs":[]}]}